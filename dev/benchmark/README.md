# Benchmark Data Preparation and Execution

This section contains scripts to prepare and run benchmark datasets for RNA sequence analysis. The benchmark datasets are generated from RNA sequences and are used to evaluate the performance of the GIN model for RNA structure classification.

## Scripts Overview

### 1. `prepare-benchmark-data.ipynb`

This Jupyter notebook is responsible for preparing the benchmark datasets. It performs the following tasks:

1. **Load and Filter Data**: Loads the RNA sequences from a CSV file and filters them based on specific criteria.
2. **Cluster Sequences**: Uses CD-HIT to cluster RNA sequences and remove redundancy.
3. **Data Cleaning**: Cleans the dataset by ensuring consistency in RNA types and removing forced RNA types.
4. **Summarize Dataset**: Provides a summary of the dataset, including counts of RNA types and unique RFAM categories.
5. **Sample Data**: Samples the dataset to create subsets for benchmark datasets, including special cases for specific RNA types.
6. **Generate Benchmark Datasets**: Creates pairwise combinations of RNA sequences for positive and negative samples and saves them as benchmark datasets.
7. **Plotting**: Generates plots to visualize the distribution of RNA types and RFAM categories in the sampled datasets.

#### Example Benchmark Datasets

- **RNA Type Classification**: Generates pairs of RNA sequences where positive samples have the same RNA type and negative samples have different RNA types and RFAMs.
- **Easy RFAM Classification**: Generates pairs of RNA sequences where positive samples have the same RNA type and RFAM, and negative samples have different RNA types and RFAMs.

The notebook also generates metadata JSON files that contain information about the sampled datasets and benchmark datasets, including creation time, version, and unique IDs.

### 2. `benchmark.py`

This script runs the benchmark on the prepared datasets, performing:

1. **Load Benchmark Datasets**: Loads datasets generated by `prepare-benchmark-data.ipynb`
2. **Generate Embeddings**: Creates graph embeddings using the GIN model
3. **Calculate Distances**: Computes distances between embeddings
4. **Evaluate Performance**: Assesses model performance using ROC curves and AUC scores
5. **Generate Reports**: Creates detailed benchmark reports and visualizations

## Parameters

### Required Parameters
- `--model-path`: Path to the trained model checkpoint (contains weights and metadata)

### Input/Output Configuration
- `--embeddings-script`: Path to embeddings script (default: "./generate_embeddings.py")
- `--benchmark-metadata`: Benchmark dataset info JSON (default: 'benchmark_datasets.json')
- `--datasets-dir`: Benchmark datasets directory (default: 'data/benchmark_datasets')
- `--results-path`: Results save path (default: "./benchmarking_results")
- `--emb-output-path`: Embeddings output path (default: 'benchmarking_results/embeddings')

### Data Processing
- `--structure-column-name`: Structure column name
- `--structure-column-num`: Structure column index
- `--header`: Files have headers? ('True'/'False', default: 'True')

### Performance Options
- `--device`: Computing device ('cuda'/'cpu')
- `--num_workers`: Parallel workers (default: 4)
- `--distance-batch-size`: Batch size for distances (default: 1000)

### Output Control
- `--save-embeddings`: Save embeddings
- `--save-distances`: Save distance calculations
- `--no-save`: Skip file saving
- `--no-log`: Skip logging
- `--skip-barplot`: Skip AUC plots
- `--skip-auc-curve`: Skip ROC curves
- `--only-needed-embeddings`: Generate required embeddings only

## How to Use

### Preparing Benchmark Datasets

1. Open the `prepare-benchmark-data.ipynb` notebook.
2. Follow the steps in the notebook to load, filter, and clean the RNA sequences.
3. Sample the dataset to create subsets for benchmark datasets.
4. Generate pairwise combinations for positive and negative samples.
5. Save the benchmark datasets and metadata.

### Running the Benchmark

1. Ensure that the benchmark datasets are prepared and saved in the specified directory.
2. Run the `benchmark.py` script with the appropriate parameters to execute the benchmark.
3. Review the generated reports to evaluate the performance of RNA classification models.

### Example Usage
```
python benchmark.py --model-path path/to/model --benchmark-metadata benchmark_datasets.json --datasets-dir data/benchmark_datasets --results-path ./benchmarking_results
```

## Directory Structure

```
benchmark/
├── prepare-benchmark-data.ipynb
├── benchmark.py
├── datasets/
│   ├── filtered_rfam_90.csv
│   ├── unpaired_rnas_rfam_benchmark-v1.tsv
│   ├── rna_type_benchmark_small-v1.tsv
│   ├── rna_type_benchmark-v1.tsv
│   ├── rna_type_benchmark_big-v1.tsv
│   ├── easy_rfam_benchmark_small-v1.tsv
│   ├── easy_rfam_benchmark-v1.tsv
│   ├── easy_rfam_benchmark_big-v1.tsv
│   ├── hard_rfam_benchmark_small-v1.tsv
│   ├── hard_rfam_benchmark-v1.tsv
│   ├── hard_rfam_benchmark_big-v1.tsv
│   └── benchmark_datasets.json
```

## Notes

- Ensure that all dependencies are installed before running the scripts.
- The `prepare-benchmark-data.ipynb` notebook requires CD-HIT to be installed for clustering RNA sequences.
- The `benchmark.py` script should be customized based on the specific requirements of the RNA classification models being evaluated.
